---
title: "6_lda"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
p_load(tidyverse)
```

# LEMMA OUT
```{r}
out <- count(unn, rowname, word) %>%
  ungroup() %>%
  mutate(hash = as.integer(as.factor(word))) %>%
  arrange(as.numeric(rowname, desc(n))) %>%
  unite("freq", hash, n, sep = ":", remove = FALSE)


out %>%
    distinct(hash, word) %>%
    arrange(hash) %>%
    write_csv("data/vw/lemma_hash.csv")


out2 <- out %>%
  split(out$rowname) %>%
  map_chr(~str_c(.$freq, collapse = " ")) %>%
  str_c("| ", .)


write_lines(out2, "data/vw/hashed_lda.vw")


out2$doc_id %>%
    unique() %>%
    write_lines("models/doc_id")
```


# VW IN
```{r}
doc_id = read_lines("models/doc_id")

# load in topic distribuiton across docs
doc = read_delim("models/doc_topic.model", delim = " ",
                 col_names = FALSE,
                 col_types = cols())

# take only last pass
n_topics = ncol(doc)
n_docs = nrow(doc) / 10
doc = tail(doc, n_docs)

# load in topic distribution across words
topic = read_delim("models/word_topic.model", delim = " ",
                   col_names = F, skip = 11,
                   col_types = cols())
topic = topic[,-c(1, ncol(topic))]

```


# DIVERGENCE FUNCTIONS FROM MALTE
```{r}
vdiff <- function(x,n,fun) sapply(n, function(i) fun(x,i))
vlag  <- function(x,n) vdiff(x,0:n,dplyr::lag)
vlead <- function(x,n) vdiff(x,0:n,dplyr::lead)

novelty2 <- function(w, cl, env) {
    # produce the lags (same shape as document)
    vlag(1:nrow(env$mat), w) %>%          
        parApply(cl = cl, X = ., MARGIN = 1,
                 function(idx, env) {
                     # then for each row (document)
                     #print(env)
                     mean(unlist(lapply(idx[2:length(idx)], function(i) {
                         #for each lag
                         #check if it's na (we're at beginning / end of data)
                         if (is.na(i)) return(NA)             
                         ## calculate surprise from past to present
                         KL.plugin(env$mat[i,], env$mat[idx[1],], unit = "log2")
                         
                     })))}, env = env)}


transience2 <- function(w, cl, env) {
    # produce the lags (same shape as document)
    vlag(1:nrow(env$mat), w) %>%          
        parApply(cl = cl, X = ., MARGIN = 1,
                 function(idx, env) {
                     # then for each row (document)
                     #print(env)
                     mean(unlist(lapply(idx[2:length(idx)], function(i) {
                         #for each lag
                         #check if it's na (we're at beginning / end of data)
                         if (is.na(i)) return(NA)             
                         ## calculate surprise from present to future
                         KL.plugin(env$mat[idx[1],], env$mat[i,], unit = "log2")
                         
                     })))}, env = env)}


z <- function(d) (d - mean(d)) / sd(d)

dataenv = new.env()
dataenv$mat = doc

cluster <- create_cluster(4) %>%
    cluster_library("entropy")


cat("[ ] Calculating novelty and transience.\n")

w = 27

lda_output = data_frame(doc_id) %>%
    mutate(
        novelty = novelty2(w, cluster, dataenv),
        transience = transience2(w, cluster, dataenv),
        resonance = novelty - transience) %>%
    filter(complete.cases(.)) %>%
    mutate(z_novelty = z(novelty),
           z_transience = z(transience),
           z_resonance = z(resonance))



res_nov_model = lm(z_resonance ~ z_novelty, data = lda_output)
lda_output$delta_R = lda_output$z_resonance - predict(res_nov_model)


lda_output %>%
    write_csv("data/nov_tra_res.csv")

```

